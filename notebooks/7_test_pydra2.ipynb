{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e27d27-efb7-43b5-b350-bfd035704913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d33772-25b7-4e2a-8b64-62c0824808e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import datetime\n",
    "import pydra\n",
    "from pydra import Workflow\n",
    "from pydra.engine.specs import File, MultiInputFile, MultiOutputFile\n",
    "import typing as ty\n",
    "from pathlib import Path\n",
    "\n",
    "# get current directory\n",
    "pydra_tutorial_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# set up output directory\n",
    "workflow_dir = Path(pydra_tutorial_dir) / 'outputs'\n",
    "workflow_out_dir = workflow_dir / '7_glm' / 'test_pydra'\n",
    "\n",
    "# create the output directory if not exit\n",
    "os.makedirs(workflow_out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f89aa52d-1d28-43ea-84e8-a2131b8d5e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'rawdata_url': str,\n",
    "        'fmriprep_url': str,\n",
    "        'return': {'event_list': MultiOutputFile, \n",
    "                   'img_list': MultiOutputFile, \n",
    "                   'mask_list': MultiOutputFile, \n",
    "                  },\n",
    "    }\n",
    ")\n",
    "def get_data(rawdata_url, fmriprep_url):\n",
    "    print(\"Download data...\")\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(t1)\n",
    "    import datalad.api as dl\n",
    "    fmriprep_path = workflow_dir / '7_glm'/ 'data'\n",
    "    rawdata_path = workflow_dir / '7_glm' / 'raw_data'\n",
    "    \n",
    "    # Install datasets to specific datapaths\n",
    "    dl.install(source=rawdata_url, path=fmriprep_path)\n",
    "    dl.install(source=fmriprep_url, path=rawdata_path)\n",
    "    \n",
    "    # get events.tsv list\n",
    "    event_list = glob.glob(os.path.join(rawdata_path, '*', 'func', '*events.tsv'))\n",
    "    event_list.sort()\n",
    "    # for i in event_list:\n",
    "    #     dl.get(i, dataset=rawdata_path)\n",
    "    # get img list\n",
    "    img_list = glob.glob(os.path.join(fmriprep_path, '*', 'func', '*space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz'))\n",
    "    img_list.sort()\n",
    "    # for i in img_list:\n",
    "    #     dl.get(i, dataset=fmriprep_path)\n",
    "    \n",
    "     # get img list\n",
    "    mask_list = glob.glob(os.path.join(fmriprep_path, '*', 'func', '*space-MNI152NLin2009cAsym_res-2_desc-brain_mask.nii.gz'))\n",
    "    mask_list.sort()\n",
    "    # for i in mask_list:\n",
    "    #     dl.get(i, dataset=fmriprep_path)\n",
    "\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return event_list, img_list, mask_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a91dfd-e067-4a12-a955-f84141cc4fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'subj_id': int,\n",
    "        'n_run': int,\n",
    "        'event_list': list, \n",
    "        'img_list': list, \n",
    "        'mask_list': list,\n",
    "        'return': {'subj_id': int, 'subj_events': list, 'subj_imgs':list, 'subj_masks':list},\n",
    "    }\n",
    ")\n",
    "def get_subj_file(subj_id, n_run, event_list, img_list, mask_list):\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"Get subject-{subj_id} file...\\n\")\n",
    "    # subj_id starts from 0\n",
    "    start = subj_id*n_run\n",
    "    end = (subj_id+1)*n_run\n",
    "    subj_events = event_list[start:end]\n",
    "    subj_imgs = img_list[start:end]\n",
    "    subj_masks = mask_list[start:end]\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return subj_id, subj_events, subj_imgs, subj_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57376ffc-9f22-4296-9f01-a9c3da1cc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'tr': float,\n",
    "        'n_scans': int,\n",
    "        'hrf_model': str,\n",
    "        'subj_id': int,\n",
    "        'subj_imgs': list,\n",
    "        'subj_events':list,\n",
    "        'return': {'design_matrices': list, 'dm_paths':list},\n",
    "    }\n",
    ")\n",
    "def get_firstlevel_dm(tr, n_scans, hrf_model, subj_id, subj_imgs, subj_events):\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(\"Get firstlevel GLM ...\\n\")\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "    from nilearn.interfaces.fmriprep import load_confounds_strategy\n",
    "    # read event file\n",
    "    events = []\n",
    "    imgs = []\n",
    "    for run_event in subj_events:\n",
    "        event = pd.read_csv(run_event, sep='\\t').fillna(0)\n",
    "        event = event[['onset', 'duration', 'trial_type']]\n",
    "        events.append(event)\n",
    "    \n",
    "    # get list of confounds directly from fmriprepped bold\n",
    "    confounds = load_confounds_strategy(subj_imgs, denoise_strategy='simple')[0]\n",
    "    \n",
    "    frame_times = np.arange(n_scans) * tr\n",
    "    design_matrices = []\n",
    "    dm_paths = []\n",
    "    for index, (ev, conf) in enumerate(zip(events, confounds)):\n",
    "        design_matrix = make_first_level_design_matrix(frame_times, ev, \n",
    "                                                       hrf_model=hrf_model,\n",
    "                                                       add_regs=conf)          \n",
    "        \n",
    "        # make sure all design matrices have the same length of column\n",
    "        # if you have a block design, this is not needed.\n",
    "        # 39 = 4(events) + 34(confounds) + 13(drift) + 1(constant)\n",
    "        assert design_matrix.shape[1] == 52, \"This design matrix has the wrong column number\"\n",
    "        # sort the column order alphabetical for contrasts\n",
    "        design_matrix = design_matrix.reindex(sorted(design_matrix.columns), axis=1)\n",
    "        dm_path = os.path.join(workflow_out_dir, 'sub-%s_run-%s_designmatrix.csv' % (subj_id, index+1))\n",
    "        design_matrix.to_csv(dm_path, index=None)\n",
    "        design_matrices.append(design_matrix)\n",
    "        dm_paths.append(dm_path)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return design_matrices, dm_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "557eec0d-fa4f-49f6-8ac7-87ba09a523ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'subj_id': int,\n",
    "        'design_matrices': list,\n",
    "        'return': {'contrasts': dict, 'contrast_plot':list},\n",
    "    }\n",
    ")\n",
    "def set_contrast(subj_id, design_matrices):\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"Set firstlevel contrast for subject-{subj_id} ...\\n\")\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from nilearn.plotting import plot_contrast_matrix\n",
    "    \n",
    "    design_matrix = design_matrices[0]\n",
    "    contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "    basic_contrasts = dict([(column, contrast_matrix[i])\n",
    "                      for i, column in enumerate(design_matrix.columns)])\n",
    "    contrasts = {\n",
    "        'pumps-control': basic_contrasts['pumps_demean'] - basic_contrasts['control_pumps_demean'],\n",
    "        'control-pumps': -basic_contrasts['control_pumps_demean'] + basic_contrasts['pumps_demean'],\n",
    "        'pumps-baseline': basic_contrasts['pumps_demean'],\n",
    "        'cash-baseline': basic_contrasts['cash_demean'],\n",
    "        'explode-baseline': basic_contrasts['explode_demean'],\n",
    "        }\n",
    "    \n",
    "    contrast_plot = []\n",
    "    for index, (contrast_id, contrast_val) in enumerate(contrasts.items()):\n",
    "        print('  Plot Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(contrasts), contrast_id))\n",
    "        contrast_plot_path = os.path.join(workflow_out_dir, 'sub-%s_firstlevel_contrast-%s.jpg' % (subj_id, contrast_id))\n",
    "        plot_contrast_matrix(contrast_val, design_matrix, output_file=contrast_plot_path)\n",
    "        contrast_plot.append(contrast_plot_path)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return contrasts, contrast_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f618f8d8-fcb9-4474-a9c6-6fd5f640cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'subj_id': int,\n",
    "        'subj_imgs': MultiInputFile,\n",
    "        'subj_masks': MultiInputFile,\n",
    "        'smoothing_fwhm': float,\n",
    "        'design_matrices': list,\n",
    "        'contrasts':dict,\n",
    "        'return': {'first_level_model': ty.Any, 'z_map_path_dict': dict},\n",
    "    }\n",
    ")\n",
    "def firstlevel_estimation(subj_id, subj_imgs, subj_masks, smoothing_fwhm, design_matrices, contrasts):\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"Start firstlevel estimation for subject-{subj_id} ...\\n\")\n",
    "    \n",
    "    import nibabel as nib\n",
    "    from nilearn.image import math_img\n",
    "    from nilearn.glm.first_level import FirstLevelModel\n",
    "    \n",
    "    print('Compute firstlevel mask...')\n",
    "    # average mask across three runs\n",
    "    mean_mask = math_img('np.mean(img, axis=-1)', img=subj_masks)\n",
    "    # binarize the mean mask\n",
    "    mask = math_img('img > 0', img=mean_mask)\n",
    "    # fit the (fixed-effects) firstlevel model with three runs simultaneously\n",
    "    first_level_model = FirstLevelModel(mask_img=mask, smoothing_fwhm=smoothing_fwhm, minimize_memory=True)\n",
    "    first_level_model = first_level_model.fit(subj_imgs, design_matrices=design_matrices)\n",
    "    \n",
    "    print('Computing contrasts...')\n",
    "    z_map_path_dict = dict.fromkeys(contrasts.keys())\n",
    "    for index, (contrast_id, contrast_val) in enumerate(contrasts.items()):\n",
    "        print('  Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(contrasts), contrast_id))\n",
    "        # Estimate the contasts. Note that the model implicitly computes a fixed\n",
    "        # effect across the two sessions\n",
    "        z_map = first_level_model.compute_contrast(\n",
    "            contrast_val, output_type='z_score')\n",
    "\n",
    "        # write the resulting stat images to file\n",
    "        z_map_path = os.path.join(workflow_out_dir, 'sub-%s_contrast-%s_z_map.nii.gz' % (subj_id, contrast_id))\n",
    "        z_map_path_dict[contrast_id] = z_map_path\n",
    "        z_map.to_filename(z_map_path)\n",
    "    \n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return first_level_model, z_map_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c8d175c-5d37-49d1-adad-3eb2e9aadd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cluster table \n",
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'subj_id': int, 'z_map_path': str, 'return': {'output_file': str}}\n",
    ")\n",
    "def cluster_table(subj_id, z_map_path):\n",
    "    \n",
    "    import nibabel as nib\n",
    "    from nilearn.reporting import get_clusters_table\n",
    "    from scipy.stats import norm\n",
    "\n",
    "    stat_img = nib.load(z_map_path)\n",
    "    output_file = os.path.join(workflow_out_dir, 'sub-%s_cluster_table.csv' % subj_id+1)\n",
    "    df = get_clusters_table(\n",
    "        stat_img, stat_threshold=norm.isf(0.001), cluster_threshold=10\n",
    "    )\n",
    "    df.to_csv(output_file, index=None)\n",
    "    return output_file\n",
    "\n",
    "# get glm report\n",
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'subj_id': int, 'model': ty.Any, 'contrasts': ty.Any, 'return': {'output_file': str}}\n",
    ")\n",
    "def glm_report(subj_id, model, contrasts):\n",
    "    from nilearn.reporting import make_glm_report\n",
    "\n",
    "    output_file = os.path.join(workflow_out_dir, 'sub-%s_glm_report.html' % subj_id+1)\n",
    "    report = make_glm_report(model, contrasts)\n",
    "    report.save_as_html(output_file)\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e9596a8-8c84-4d59-a111-7deda4961694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodename=wf_firstlevel\n",
      "cache_dir=None\n",
      "cache_locations=None\n",
      "nodename=get_subj_file\n",
      "cache_dir=None\n",
      "cache_locations=None\n",
      "nodename=get_firstlevel_dm\n",
      "cache_dir=None\n",
      "cache_locations=None\n",
      "nodename=set_contrast\n",
      "cache_dir=None\n",
      "cache_locations=None\n",
      "nodename=firstlevel_estimation\n",
      "cache_dir=None\n",
      "cache_locations=None\n"
     ]
    }
   ],
   "source": [
    "# initiate the first-level GLM workflow\n",
    "wf_firstlevel = Workflow(\n",
    "    name='wf_firstlevel',\n",
    "    input_spec=[\n",
    "        'subj_id',\n",
    "        'n_run',\n",
    "        'tr',\n",
    "        'n_scans',\n",
    "        'hrf_model',\n",
    "        'event_list', \n",
    "        'img_list', \n",
    "        'mask_list',\n",
    "        'smoothing_fwhm',\n",
    "        'output_dir'\n",
    "    ],\n",
    ")\n",
    "\n",
    "wf_firstlevel.split('subj_id')\n",
    "# add task - get_subj_file\n",
    "wf_firstlevel.add(\n",
    "    get_subj_file(\n",
    "        name = \"get_subj_file\",\n",
    "        subj_id = wf_firstlevel.lzin.subj_id, \n",
    "        n_run = wf_firstlevel.lzin.n_run, \n",
    "        event_list = wf_firstlevel.lzin.event_list, \n",
    "        img_list = wf_firstlevel.lzin.img_list, \n",
    "        mask_list = wf_firstlevel.lzin.mask_list\n",
    "    )\n",
    ")\n",
    "\n",
    "# add task - get_firstlevel_dm\n",
    "wf_firstlevel.add(\n",
    "    get_firstlevel_dm(\n",
    "        name = \"get_firstlevel_dm\",\n",
    "        tr = wf_firstlevel.lzin.tr, \n",
    "        n_scans = wf_firstlevel.lzin.n_scans, \n",
    "        hrf_model = wf_firstlevel.lzin.hrf_model, \n",
    "        subj_id = wf_firstlevel.get_subj_file.lzout.subj_id, \n",
    "        subj_imgs = wf_firstlevel.get_subj_file.lzout.subj_imgs, \n",
    "        subj_events = wf_firstlevel.get_subj_file.lzout.subj_events, \n",
    "    )\n",
    ")\n",
    "\n",
    "# add task - set_contrast\n",
    "wf_firstlevel.add(\n",
    "    set_contrast(\n",
    "        name = \"set_contrast\",\n",
    "        subj_id = wf_firstlevel.get_subj_file.lzout.subj_id,\n",
    "        design_matrices = wf_firstlevel.get_firstlevel_dm.lzout.design_matrices\n",
    "    )\n",
    ")\n",
    "\n",
    "# add task - firstlevel_estimation\n",
    "wf_firstlevel.add(\n",
    "    firstlevel_estimation(\n",
    "        name = \"firstlevel_estimation\",\n",
    "        subj_id = wf_firstlevel.get_subj_file.lzout.subj_id, \n",
    "        subj_imgs = wf_firstlevel.get_subj_file.lzout.subj_imgs, \n",
    "        subj_masks = wf_firstlevel.get_subj_file.lzout.subj_masks, \n",
    "        smoothing_fwhm = wf_firstlevel.lzin.smoothing_fwhm, \n",
    "        design_matrices = wf_firstlevel.get_firstlevel_dm.lzout.design_matrices, \n",
    "        contrasts = wf_firstlevel.set_contrast.lzout.contrasts\n",
    "    )\n",
    ")\n",
    "\n",
    "wf_firstlevel.combine('subj_id')\n",
    "# specify output\n",
    "wf_firstlevel.set_output(\n",
    "    [\n",
    "        ('first_level_designmatrices', wf_firstlevel.get_firstlevel_dm.lzout.design_matrices),\n",
    "        ('first_level_dm_paths', wf_firstlevel.get_firstlevel_dm.lzout.dm_paths),\n",
    "        ('first_level_contrast', wf_firstlevel.set_contrast.lzout.contrasts),\n",
    "        ('first_level_contrast_plot', wf_firstlevel.set_contrast.lzout.contrast_plot),\n",
    "        ('first_level_model_list', wf_firstlevel.firstlevel_estimation.lzout.first_level_model),\n",
    "        ('first_level_z_map_dict_list', wf_firstlevel.firstlevel_estimation.lzout.z_map_path_dict),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cb0fa41-da13-476f-9746-77c39eb65821",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'n_subj': int, 'return': {'design_matrix': ty.Any}}\n",
    ")\n",
    "def get_secondlevel_dm(n_subj):\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"\\nGet secondlevel design matrix ...\\n\")\n",
    "    import pandas as pd\n",
    "    design_matrix = pd.DataFrame([1] * n_subj,columns=['intercept'])\n",
    "    dm_path = os.path.join(workflow_out_dir, 'secondlevel_designmatrix.csv')\n",
    "    design_matrix.to_csv(dm_path, index=None)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return design_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69194062-fb3e-473a-94f4-e1c4b8d294d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'second_level_input': ty.Any, 'design_matrix': ty.Any, 'firstlevel_contrast':list, \n",
    "     'return': {'secondlevel_mask': ty.Any, 'stat_maps_dict': dict}}\n",
    ")\n",
    "def secondlevel_estimation(second_level_input, design_matrix, firstlevel_contrast):\n",
    "    \"\"\" task to estimate the second level\n",
    "    Parameters\n",
    "    ----------\n",
    "    second_level_input : list\n",
    "        the list of FirstLevelModel\n",
    "    design_matrix : ty.Any\n",
    "        a pandas.DataFrame that specifies the second level design\n",
    "    firstlevel_contrast : dict\n",
    "        a dictionary of contrasts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    secondlevel_mask : mask from SecondLevelModel\n",
    "        \n",
    "    stat_maps_dict : dict\n",
    "        \n",
    "    \"\"\"\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"\\nStart secondlevel estimation ...\\n\")\n",
    "    from nilearn.glm.second_level import SecondLevelModel\n",
    "    second_level_model = SecondLevelModel()\n",
    "    second_level_model = second_level_model.fit(second_level_input, design_matrix=design_matrix)\n",
    "    secondlevel_mask = second_level_model.masker_.mask_img_\n",
    "    \n",
    "    print('Computing contrasts...')\n",
    "    stat_maps_dict = {}\n",
    "    for index, (contrast_id, contrast_val) in enumerate(firstlevel_contrast[0].items()):\n",
    "        print('  Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(firstlevel_contrast), contrast_id))\n",
    "        # Estimate the contasts. Note that the model implicitly computes a fixed\n",
    "        # effect across the two sessions\n",
    "        z_map = second_level_model.compute_contrast(first_level_contrast=contrast_val, output_type='z_score')\n",
    "        print(\"got z-map\")\n",
    "        # write the resulting stat images to file\n",
    "        z_image_path = os.path.join(workflow_out_dir, 'secondlevel_contrast-%s_z_map.nii.gz' % contrast_id)\n",
    "        print(\"put z-map path to dict\")\n",
    "        stat_maps_dict[contrast_id] = z_image_path\n",
    "        print(\"save file to path\")\n",
    "        z_map.to_filename(z_image_path)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return secondlevel_mask, stat_maps_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa9d7cae-d692-4efb-8c54-c18130475487",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'stat_maps_dict': ty.Any, 'threshold': float, 'cluster_threshold': int, \n",
    "     'return': {'thresholded_map_dict': dict, 'plot_contrast_dict': dict}}\n",
    ")\n",
    "def cluster_thresholding(stat_maps_dict, threshold, cluster_threshold):\n",
    "    print(\"new\")\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"\\nStart cluster thresholding ...\\n\")\n",
    "    from nilearn.image import threshold_img\n",
    "    from nilearn import plotting\n",
    "    thresholded_map_dict = dict.fromkeys(stat_maps_dict.keys())\n",
    "    plot_contrast_dict = dict.fromkeys(stat_maps_dict.keys())\n",
    "    for index, (stats_id, stats_val) in enumerate(stat_maps_dict.items()):\n",
    "        print('  Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(stat_maps_dict), stats_id))\n",
    "        thresholded_map = threshold_img(\n",
    "            img = stats_val,\n",
    "            threshold=threshold,\n",
    "            cluster_threshold=cluster_threshold,\n",
    "            two_sided=True,\n",
    "        )\n",
    "        thresholded_map_path = path.join(workflow_out_dir, 'secondlevel_cluster_thresholded_contrast-%s_z_map.nii.gz' % stats_id)\n",
    "        thresholded_map_dict[stats_id] = thresholded_map_path\n",
    "        thresholded_map.to_filename(thresholded_map_path)\n",
    "        plot_path = os.path.join(workflow_out_dir, \n",
    "                                   'secondlevel_cluster_thresholded_contrast-%s_zmap.jpg' % stats_id)\n",
    "        plot_contrast_dict[stats_id] = plot_path\n",
    "        plotting.plot_stat_map(thresholded_map, cut_coords=[0],\n",
    "                               title='Cluster Thresholded z map',\n",
    "                               output_file=plot_path)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return thresholded_map_dict, plot_contrast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8696f4e-3009-400c-a2c4-10a4e24c9340",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'input1':ty.Any,\n",
    "        'return': {'out':ty.Any}\n",
    "    }\n",
    ")\n",
    "def test(input1):\n",
    "    print(\"testing...\")\n",
    "    out = input1\n",
    "    print(f\"out={out}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3665604a-215e-4943-9222-a808a9773548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodename=wf\n",
      "cache_dir=None\n",
      "cache_locations=None\n",
      "nodename=get_data\n",
      "cache_dir=None\n",
      "cache_locations=None\n",
      "nodename=get_secondlevel_dm\n",
      "cache_dir=None\n",
      "cache_locations=None\n",
      "nodename=secondlevel_estimation\n",
      "cache_dir=None\n",
      "cache_locations=None\n"
     ]
    }
   ],
   "source": [
    "wf = Workflow(\n",
    "    name='wf',\n",
    "    input_spec=['subj_id','rawdata_url', 'fmriprep_url', 'smoothing_fwhm', 'output_dir'],\n",
    ")\n",
    "\n",
    "\n",
    "wf.inputs.rawdata_url = 'https://github.com/OpenNeuroDerivatives/ds000001-fmriprep.git'\n",
    "wf.inputs.fmriprep_url = 'https://github.com/OpenNeuroDatasets/ds000001.git'\n",
    "wf.inputs.smoothing_fwhm = 5.0\n",
    "wf.inputs.output_dir = workflow_out_dir\n",
    "\n",
    "wf.add(\n",
    "    get_data(\n",
    "        name = \"get_data\",\n",
    "        rawdata_url = wf.lzin.rawdata_url, \n",
    "        fmriprep_url = wf.lzin.fmriprep_url)\n",
    ")\n",
    "\n",
    "n_subj = 2\n",
    "wf_firstlevel.inputs.subj_id = [x for x in range(n_subj)]\n",
    "wf_firstlevel.inputs.n_run = 3\n",
    "wf_firstlevel.inputs.tr = 2.3\n",
    "wf_firstlevel.inputs.n_scans = 300\n",
    "wf_firstlevel.inputs.hrf_model = 'glover'\n",
    "wf_firstlevel.inputs.event_list = wf.get_data.lzout.event_list\n",
    "wf_firstlevel.inputs.img_list = wf.get_data.lzout.img_list\n",
    "wf_firstlevel.inputs.mask_list = wf.get_data.lzout.mask_list\n",
    "wf_firstlevel.inputs.smoothing_fwhm = wf.lzin.smoothing_fwhm\n",
    "wf_firstlevel.inputs.output_dir = wf.lzin.output_dir\n",
    "wf.add(wf_firstlevel)\n",
    "\n",
    "wf.add(\n",
    "    get_secondlevel_dm(\n",
    "        name = \"get_secondlevel_dm\",\n",
    "        n_subj = n_subj\n",
    "    )\n",
    ")\n",
    "\n",
    "wf.add(\n",
    "    secondlevel_estimation(\n",
    "        name = \"secondlevel_estimation\",\n",
    "        second_level_input = wf.wf_firstlevel.lzout.first_level_model_list, \n",
    "        design_matrix = wf.get_secondlevel_dm.lzout.design_matrix, \n",
    "        firstlevel_contrast = wf.wf_firstlevel.lzout.first_level_contrast,\n",
    "    )\n",
    ")\n",
    "\n",
    "# wf.add(\n",
    "#     test(\n",
    "#         name = \"test\",\n",
    "#         input1 = wf.secondlevel_estimation.lzout.stat_maps_dict, \n",
    "#     )\n",
    "# )\n",
    "# wf.add(\n",
    "#     cluster_thresholding(\n",
    "#         name = \"cluster_thresholding\",\n",
    "#         stat_maps_dict = wf.secondlevel_estimation.lzout.stat_maps_dict, \n",
    "#         threshold = 2.3, \n",
    "#         cluster_threshold = 10)\n",
    "# )\n",
    "\n",
    "wf.set_output(\n",
    "    [\n",
    "        # ('first_level_model_list', wf.wf_firstlevel.lzout.first_level_model_list),\n",
    "        ('first_level_z_maps', wf.wf_firstlevel.lzout.first_level_z_map_dict_list),\n",
    "        ('second_level_stats_map', wf.secondlevel_estimation.lzout.stat_maps_dict)\n",
    "        # ('second_level_clusterthresholding_result', wf.cluster_thresholding.lzout.thresholded_map_dict),\n",
    "        # ('second_level_clusterthresholding_plot', wf.cluster_thresholding.lzout.plot_contrast_dict)\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57267da7-70e8-4588-93de-ef426803bd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self=<pydra.engine.submitter.Submitter object at 0x7fa368853f10>\n",
      "runnable=wf\n",
      "rerun=False\n",
      "check <pydra.engine.submitter.Submitter object at 0x7fa368853f10> is_workflow\n",
      "\n",
      "Get secondlevel design matrix ...\n",
      "\n",
      "Download data...\n",
      "2022-08-20 13:18:22.052773\n",
      "0:00:00.448040\n",
      "0:00:00.720243\n",
      "Get subject-0 file...\n",
      "Get subject-1 file...\n",
      "\n",
      "\n",
      "0:00:00.005556\n",
      "0:00:00.005593\n",
      "Get firstlevel GLM ...\n",
      "\n",
      "Get firstlevel GLM ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/__init__.py:56: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  'It may change in any future release of Nilearn.', FutureWarning)\n",
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/__init__.py:56: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  'It may change in any future release of Nilearn.', FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:01.460619\n",
      "0:00:01.501360\n",
      "Set firstlevel contrast for subject-0 ...\n",
      "\n",
      "Set firstlevel contrast for subject-1 ...\n",
      "\n",
      "  Plot Contrast  1 out of 5: pumps-control  Plot Contrast  1 out of 5: pumps-control\n",
      "\n",
      "  Plot Contrast  2 out of 5: control-pumps  Plot Contrast  2 out of 5: control-pumps\n",
      "\n",
      "  Plot Contrast  3 out of 5: pumps-baseline\n",
      "  Plot Contrast  3 out of 5: pumps-baseline\n",
      "  Plot Contrast  4 out of 5: cash-baseline\n",
      "  Plot Contrast  4 out of 5: cash-baseline\n",
      "  Plot Contrast  5 out of 5: explode-baseline\n",
      "  Plot Contrast  5 out of 5: explode-baseline\n",
      "0:00:07.689880\n",
      "0:00:07.654233\n",
      "Start firstlevel estimation for subject-0 ...\n",
      "\n",
      "Start firstlevel estimation for subject-1 ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/__init__.py:56: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  'It may change in any future release of Nilearn.', FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute firstlevel mask...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/__init__.py:56: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  'It may change in any future release of Nilearn.', FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute firstlevel mask...\n",
      "Computing contrasts...\n",
      "  Contrast  1 out of 5: pumps-control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py:657: UserWarning: One contrast given, assuming it for all 3 runs\n",
      "  warn('One contrast given, assuming it for all %d runs' % n_runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Contrast  2 out of 5: control-pumps\n",
      "Computing contrasts...\n",
      "  Contrast  1 out of 5: pumps-control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py:657: UserWarning: One contrast given, assuming it for all 3 runs\n",
      "  warn('One contrast given, assuming it for all %d runs' % n_runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Contrast  3 out of 5: pumps-baseline\n",
      "  Contrast  2 out of 5: control-pumps\n",
      "  Contrast  4 out of 5: cash-baseline\n",
      "  Contrast  3 out of 5: pumps-baseline\n",
      "  Contrast  5 out of 5: explode-baseline\n",
      "  Contrast  4 out of 5: cash-baseline\n",
      "0:02:57.016853\n",
      "  Contrast  5 out of 5: explode-baseline\n",
      "0:03:01.201078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/__init__.py:56: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  'It may change in any future release of Nilearn.', FutureWarning)\n",
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/__init__.py:56: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  'It may change in any future release of Nilearn.', FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start secondlevel estimation ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py:657: UserWarning: One contrast given, assuming it for all 3 runs\n",
      "  warn('One contrast given, assuming it for all %d runs' % n_runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing contrasts...\n",
      "  Contrast  1 out of 2: pumps-control\n",
      "got z-map\n",
      "put z-map path to dict\n",
      "save file to path\n",
      "  Contrast  2 out of 2: control-pumps\n",
      "got z-map\n",
      "put z-map path to dict\n",
      "save file to path\n",
      "  Contrast  3 out of 2: pumps-baseline\n",
      "got z-map\n",
      "put z-map path to dict\n",
      "save file to path\n",
      "  Contrast  4 out of 2: cash-baseline\n",
      "got z-map\n",
      "put z-map path to dict\n",
      "save file to path\n",
      "  Contrast  5 out of 2: explode-baseline\n",
      "got z-map\n",
      "put z-map path to dict\n",
      "save file to path\n",
      "0:00:19.933270\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'errored'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wr/x5xt_yqs2cvc_gb3sf147lvc0000gn/T/ipykernel_76274/815201263.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mSubmitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_procs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msubmitter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msubmitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GDrive/GitHub/pydra/pydra/engine/submitter.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, runnable, cache_locations, rerun)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"runnable={runnable}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"rerun={rerun}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit_from_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunnable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrerun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pydra/lib/python3.7/site-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     88\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pydra/lib/python3.7/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pydra/lib/python3.7/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GDrive/GitHub/pydra/pydra/engine/submitter.py\u001b[0m in \u001b[0;36msubmit_from_call\u001b[0;34m(self, runnable, rerun)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0;32mawait\u001b[0m \u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrerun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrerun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;31m# 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GDrive/GitHub/pydra/pydra/engine/core.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, submitter, rerun, **kwargs)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m                 \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrerun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrerun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collect_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m                 \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GDrive/GitHub/pydra/pydra/engine/core.py\u001b[0m in \u001b[0;36m_collect_outputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all connections must be lazy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                 \u001b[0mval_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0moutput_wf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GDrive/GitHub/pydra/pydra/engine/specs.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, wf, state_index)\u001b[0m\n\u001b[1;32m    762\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mresults_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrored\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error from get_value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'errored'"
     ]
    }
   ],
   "source": [
    "from pydra import Submitter\n",
    "\n",
    "with Submitter(plugin='cf', n_procs=8) as submitter:\n",
    "    submitter(wf)\n",
    "\n",
    "results = wf.result()\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
