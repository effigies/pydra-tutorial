{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c8ffca2-f7d5-4ac3-86ed-42fe5ad9148a",
   "metadata": {},
   "source": [
    "# 7. Multilevel GLM (from Nilearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ad6d8a-cb2c-447d-9e25-54fc5bf10a94",
   "metadata": {},
   "source": [
    "In this tutorial, we demonstrate how to write pydra tasks for the first and second level GLM in Nilearn. We use the data from [Balloon Analog Risk-taking Task](https://openneuro.org/datasets/ds000001/versions/1.0.0). \n",
    "Basic information about this dataset:\n",
    "- 16 subjects\n",
    "- 3 runs\n",
    "- functional scan TR: 2.3 \n",
    "- num of functional scan: 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f0479cc-93eb-4e40-872f-57a07a062e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6e1690-018b-491b-9d8d-8c9885a4376e",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Import packages that will be used globally and set up output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20eb3282-280f-4b8d-bf16-ef49781a90ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import datetime\n",
    "import pydra\n",
    "from pydra import Workflow\n",
    "from pydra.engine.specs import File, MultiInputFile, MultiOutputFile\n",
    "import typing as ty\n",
    "from pathlib import Path\n",
    "\n",
    "# get current directory\n",
    "pydra_tutorial_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# set up output directory\n",
    "workflow_dir = Path(pydra_tutorial_dir) / 'outputs'\n",
    "workflow_out_dir = workflow_dir / '7_glm' /'results'\n",
    "\n",
    "# create the output directory if not exit\n",
    "os.makedirs(workflow_out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d8928-4710-4159-ae27-640f1d74bb12",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "\n",
    "[DataLad](http://handbook.datalad.org/en/latest/index.htmlhttp://handbook.datalad.org/en/latest/index.html) is often used in those cases to download data. Here we use its [Python API](http://docs.datalad.org/en/latest/modref.htmlhttp://docs.datalad.org/en/latest/modref.html).\n",
    "\n",
    "We need the following data: \n",
    "\n",
    "1. event information (raw data)\n",
    "2. preprocessed image data (fmriprep)\n",
    "3. confounds (fmriprep)\n",
    "\n",
    "By `api.install`, datalad downloads all symlinks without storing the actual data locally. We can then use `api.get` to get the data we need for our analysis. \n",
    "We need to get three types of data from two folders:\n",
    "\n",
    "1. `*events.tsv` from `rawdata_path`\n",
    "2. `*space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz` from `fmriprep_path`\n",
    "3. `*desc-confounds_timeseries.tsv` from `fmriprep_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40966ba9-9225-4464-b401-7f07e052708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmriprep_path = workflow_out_dir / 'data'\n",
    "rawdata_path = workflow_out_dir / 'raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dabc0fb-3b56-4f65-875b-9b9ce37da3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'rawdata_url': str,\n",
    "        'fmriprep_url': str,\n",
    "        'return': {'event_list': MultiOutputFile, \n",
    "                   'img_list': MultiOutputFile, \n",
    "                   'mask_list': MultiOutputFile, \n",
    "                  },\n",
    "    }\n",
    ")\n",
    "def get_data(rawdata_url, fmriprep_url):\n",
    "    print(\"Download data...\")\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(t1)\n",
    "    import datalad.api as dl\n",
    "    fmriprep_path = workflow_dir / '7_glm'/ 'data'\n",
    "    rawdata_path = workflow_dir / '7_glm' / 'raw_data'\n",
    "    \n",
    "    # Install datasets to specific datapaths\n",
    "    dl.install(source=rawdata_url, path=fmriprep_path)\n",
    "    dl.install(source=fmriprep_url, path=rawdata_path)\n",
    "    \n",
    "    # get events.tsv list\n",
    "    event_list = glob.glob(os.path.join(rawdata_path, '*', 'func', '*events.tsv'))\n",
    "    event_list.sort()\n",
    "    # for i in event_list:\n",
    "    #     dl.get(i, dataset=rawdata_path)\n",
    "    # get img list\n",
    "    img_list = glob.glob(os.path.join(fmriprep_path, '*', 'func', '*space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz'))\n",
    "    img_list.sort()\n",
    "    # for i in img_list:\n",
    "    #     dl.get(i, dataset=fmriprep_path)\n",
    "    \n",
    "     # get img list\n",
    "    mask_list = glob.glob(os.path.join(fmriprep_path, '*', 'func', '*space-MNI152NLin2009cAsym_res-2_desc-brain_mask.nii.gz'))\n",
    "    mask_list.sort()\n",
    "    # for i in mask_list:\n",
    "    #     dl.get(i, dataset=fmriprep_path)\n",
    "\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return event_list, img_list, mask_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb2990-9b66-4ddc-ad7f-d9e573877257",
   "metadata": {},
   "source": [
    "## First-Level GLM\n",
    "\n",
    "We conduct the first level GLM for each run on every subject."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efe11a1-4da8-4691-ac7e-32257b3f34d7",
   "metadata": {},
   "source": [
    "### Get events, preproc_bold, and confounds for each subject\n",
    "\n",
    "each subject will have a list of three (run) of those files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f04869-993a-41b4-9cce-fea2407e0127",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'subj_id': int,\n",
    "        'n_run': int,\n",
    "        'event_list': list, \n",
    "        'img_list': list, \n",
    "        'mask_list': list,\n",
    "        'return': {'subj_id': int, 'subj_events': list, 'subj_imgs':list, 'subj_masks':list},\n",
    "    }\n",
    ")\n",
    "def get_subj_file(subj_id, n_run, event_list, img_list, mask_list):\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"\\nGet subject-{subj_id+1} file...\\n\")\n",
    "    # subj_id starts from 0\n",
    "    start = subj_id*n_run\n",
    "    end = (subj_id+1)*n_run\n",
    "    subj_events = event_list[start:end]\n",
    "    subj_imgs = img_list[start:end]\n",
    "    subj_masks = mask_list[start:end]\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return subj_id, subj_events, subj_imgs, subj_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83636911-1090-49f6-a36e-c88588ad24e6",
   "metadata": {},
   "source": [
    "### Get the first-level design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a4f6669-1092-4da2-80fa-375c849952d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'tr': float,\n",
    "        'n_scans': int,\n",
    "        'hrf_model': str,\n",
    "        'subj_id': int,\n",
    "        'subj_imgs': list,\n",
    "        'subj_events':list,\n",
    "        'return': {'design_matrices': list, 'dm_paths':list},\n",
    "    }\n",
    ")\n",
    "def get_firstlevel_dm(tr, n_scans, hrf_model, subj_id, subj_imgs, subj_events):\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"\\nGet subject-{subj_id+1} firstlevel GLM ...\\n\")\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "    from nilearn.interfaces.fmriprep import load_confounds_strategy\n",
    "    # read event file\n",
    "    events = []\n",
    "    imgs = []\n",
    "    for run_event in subj_events:\n",
    "        event = pd.read_csv(run_event, sep='\\t').fillna(0)\n",
    "        event = event[['onset', 'duration', 'trial_type']]\n",
    "        events.append(event)\n",
    "    \n",
    "    # get list of confounds directly from fmriprepped bold\n",
    "    confounds = load_confounds_strategy(subj_imgs, denoise_strategy='simple')[0]\n",
    "    \n",
    "    frame_times = np.arange(n_scans) * tr\n",
    "    design_matrices = []\n",
    "    dm_paths = []\n",
    "    for index, (ev, conf) in enumerate(zip(events, confounds)):\n",
    "        design_matrix = make_first_level_design_matrix(frame_times, ev, \n",
    "                                                       hrf_model=hrf_model,\n",
    "                                                       add_regs=conf)          \n",
    "        \n",
    "        # make sure all design matrices have the same length of column\n",
    "        # if you have a block design, this is not needed.\n",
    "        # 39 = 4(events) + 34(confounds) + 13(drift) + 1(constant)\n",
    "        assert design_matrix.shape[1] == 52, \"This design matrix has the wrong column number\"\n",
    "        # sort the column order alphabetical for contrasts\n",
    "        design_matrix = design_matrix.reindex(sorted(design_matrix.columns), axis=1)\n",
    "        dm_path = os.path.join(workflow_out_dir, 'sub-%s_run-%s_designmatrix.csv' % (subj_id+1, index+1))\n",
    "        design_matrix.to_csv(dm_path, index=None)\n",
    "        design_matrices.append(design_matrix)\n",
    "        dm_paths.append(dm_path)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return design_matrices, dm_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8a6d71-2c84-4587-8b79-e3012faea946",
   "metadata": {},
   "source": [
    "### Set up the first-level contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bea4d73-93cd-4929-86c1-76c4c89fb9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'subj_id': int,\n",
    "        'design_matrices': list,\n",
    "        'return': {'contrasts': dict, 'contrast_plot':list},\n",
    "    }\n",
    ")\n",
    "def set_contrast(subj_id, design_matrices):\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"\\nSet firstlevel contrast for subject-{subj_id+1} ...\\n\")\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from nilearn.plotting import plot_contrast_matrix\n",
    "    \n",
    "    design_matrix = design_matrices[0]\n",
    "    contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "    basic_contrasts = dict([(column, contrast_matrix[i])\n",
    "                      for i, column in enumerate(design_matrix.columns)])\n",
    "    contrasts = {\n",
    "        'pumps-control': basic_contrasts['pumps_demean'] - basic_contrasts['control_pumps_demean'],\n",
    "        'control-pumps': -basic_contrasts['control_pumps_demean'] + basic_contrasts['pumps_demean'],\n",
    "        'pumps-baseline': basic_contrasts['pumps_demean'],\n",
    "        'cash-baseline': basic_contrasts['cash_demean'],\n",
    "        'explode-baseline': basic_contrasts['explode_demean']\n",
    "        }\n",
    "    \n",
    "    contrast_plot = []\n",
    "    for index, (contrast_id, contrast_val) in enumerate(contrasts.items()):\n",
    "        print('  Plot Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(contrasts), contrast_id))\n",
    "        contrast_plot_path = os.path.join(workflow_out_dir, 'sub-%s_firstlevel_contrast-%s.jpg' % (subj_id+1, contrast_id))\n",
    "        plot_contrast_matrix(contrast_val, design_matrix, output_file=contrast_plot_path)\n",
    "        contrast_plot.append(contrast_plot_path)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return contrasts, contrast_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b2360-48bc-486b-8d4c-c85ae347848e",
   "metadata": {},
   "source": [
    "### Fit the first level GLM with fixed-effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "026781b0-cfa9-40b9-a3e0-004da0a98a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'subj_id': int,\n",
    "        'subj_imgs': MultiInputFile,\n",
    "        'subj_masks': MultiInputFile,\n",
    "        'smoothing_fwhm': float,\n",
    "        'design_matrices': list,\n",
    "        'contrasts':dict,\n",
    "        'return': {'first_level_model': ty.Any, 'z_map_path_dict': dict},\n",
    "    }\n",
    ")\n",
    "def firstlevel_estimation(subj_id, subj_imgs, subj_masks, smoothing_fwhm, design_matrices, contrasts):\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"\\nStart firstlevel estimation for subject-{subj_id+1} ...\\n\")\n",
    "    \n",
    "    import nibabel as nib\n",
    "    from nilearn.image import math_img\n",
    "    from nilearn.glm.first_level import FirstLevelModel\n",
    "    \n",
    "    print('Compute firstlevel mask...')\n",
    "    # average mask across three runs\n",
    "    mean_mask = math_img('np.mean(img, axis=-1)', img=subj_masks)\n",
    "    # binarize the mean mask\n",
    "    mask = math_img('img > 0', img=mean_mask)\n",
    "    # fit the (fixed-effects) firstlevel model with three runs simultaneously\n",
    "    first_level_model = FirstLevelModel(mask_img=mask, smoothing_fwhm=smoothing_fwhm, minimize_memory=True)\n",
    "    first_level_model = first_level_model.fit(subj_imgs, design_matrices=design_matrices)\n",
    "    \n",
    "    print('Computing contrasts...')\n",
    "    z_map_path_dict = dict.fromkeys(contrasts.keys())\n",
    "    for index, (contrast_id, contrast_val) in enumerate(contrasts.items()):\n",
    "        print('  Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(contrasts), contrast_id))\n",
    "        # Estimate the contasts. Note that the model implicitly computes a fixed\n",
    "        # effect across the two sessions\n",
    "        z_map = first_level_model.compute_contrast(\n",
    "            contrast_val, output_type='z_score')\n",
    "\n",
    "        # write the resulting stat images to file\n",
    "        z_map_path = os.path.join(workflow_out_dir, 'sub-%s_contrast-%s_z_map.nii.gz' % (subj_id+1, contrast_id))\n",
    "        z_map_path_dict[contrast_id] = z_map_path\n",
    "        z_map.to_filename(z_map_path)\n",
    "    \n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return first_level_model, z_map_path_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00645f2-85cc-466d-ba79-a562eb195b03",
   "metadata": {},
   "source": [
    "### Get cluster table and glm report\n",
    "\n",
    "For publication purposes, we obtain a cluster table and a summary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e27932cf-43dc-4fc9-afad-44d19890ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cluster table \n",
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'subj_id': int, 'z_map_path': str, 'return': {'output_file': str}}\n",
    ")\n",
    "def cluster_table(subj_id, z_map_path):\n",
    "    \n",
    "    import nibabel as nib\n",
    "    from nilearn.reporting import get_clusters_table\n",
    "    from scipy.stats import norm\n",
    "\n",
    "    stat_img = nib.load(z_map_path)\n",
    "    output_file = os.path.join(workflow_out_dir, 'sub-%s_cluster_table.csv' % subj_id+1)\n",
    "    df = get_clusters_table(\n",
    "        stat_img, stat_threshold=norm.isf(0.001), cluster_threshold=10\n",
    "    )\n",
    "    df.to_csv(output_file, index=None)\n",
    "    return output_file\n",
    "\n",
    "# get glm report\n",
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'subj_id': int, 'model': ty.Any, 'contrasts': ty.Any, 'return': {'output_file': str}}\n",
    ")\n",
    "def glm_report(subj_id, model, contrasts):\n",
    "    from nilearn.reporting import make_glm_report\n",
    "\n",
    "    output_file = os.path.join(workflow_out_dir, 'sub-%s_glm_report.html' % subj_id+1)\n",
    "    report = make_glm_report(model, contrasts)\n",
    "    report.save_as_html(output_file)\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7b6eaa-53d8-4af2-8459-dc94e1ac8621",
   "metadata": {},
   "source": [
    "### Create the first-level GLM workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ea7f051-7ce8-4339-be56-9881272c75ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the first-level GLM workflow\n",
    "wf_firstlevel = Workflow(\n",
    "    name='wf_firstlevel',\n",
    "    input_spec=[\n",
    "        'subj_id',\n",
    "        'n_run',\n",
    "        'tr',\n",
    "        'n_scans',\n",
    "        'hrf_model',\n",
    "        'event_list', \n",
    "        'img_list', \n",
    "        'mask_list',\n",
    "        'smoothing_fwhm',\n",
    "        'output_dir'\n",
    "    ],\n",
    ")\n",
    "\n",
    "wf_firstlevel.split('subj_id')\n",
    "# add task - get_subj_file\n",
    "wf_firstlevel.add(\n",
    "    get_subj_file(\n",
    "        name = \"get_subj_file\",\n",
    "        subj_id = wf_firstlevel.lzin.subj_id, \n",
    "        n_run = wf_firstlevel.lzin.n_run, \n",
    "        event_list = wf_firstlevel.lzin.event_list, \n",
    "        img_list = wf_firstlevel.lzin.img_list, \n",
    "        mask_list = wf_firstlevel.lzin.mask_list\n",
    "    )\n",
    ")\n",
    "\n",
    "# add task - get_firstlevel_dm\n",
    "wf_firstlevel.add(\n",
    "    get_firstlevel_dm(\n",
    "        name = \"get_firstlevel_dm\",\n",
    "        tr = wf_firstlevel.lzin.tr, \n",
    "        n_scans = wf_firstlevel.lzin.n_scans, \n",
    "        hrf_model = wf_firstlevel.lzin.hrf_model, \n",
    "        subj_id = wf_firstlevel.get_subj_file.lzout.subj_id, \n",
    "        subj_imgs = wf_firstlevel.get_subj_file.lzout.subj_imgs, \n",
    "        subj_events = wf_firstlevel.get_subj_file.lzout.subj_events, \n",
    "    )\n",
    ")\n",
    "\n",
    "# add task - set_contrast\n",
    "wf_firstlevel.add(\n",
    "    set_contrast(\n",
    "        name = \"set_contrast\",\n",
    "        subj_id = wf_firstlevel.get_subj_file.lzout.subj_id,\n",
    "        design_matrices = wf_firstlevel.get_firstlevel_dm.lzout.design_matrices\n",
    "    )\n",
    ")\n",
    "\n",
    "# add task - firstlevel_estimation\n",
    "wf_firstlevel.add(\n",
    "    firstlevel_estimation(\n",
    "        name = \"firstlevel_estimation\",\n",
    "        subj_id = wf_firstlevel.get_subj_file.lzout.subj_id, \n",
    "        subj_imgs = wf_firstlevel.get_subj_file.lzout.subj_imgs, \n",
    "        subj_masks = wf_firstlevel.get_subj_file.lzout.subj_masks, \n",
    "        smoothing_fwhm = wf_firstlevel.lzin.smoothing_fwhm, \n",
    "        design_matrices = wf_firstlevel.get_firstlevel_dm.lzout.design_matrices, \n",
    "        contrasts = wf_firstlevel.set_contrast.lzout.contrasts\n",
    "    )\n",
    ")\n",
    "\n",
    "wf_firstlevel.combine('subj_id')\n",
    "# specify output\n",
    "wf_firstlevel.set_output(\n",
    "    [\n",
    "        ('first_level_designmatrices', wf_firstlevel.get_firstlevel_dm.lzout.design_matrices),\n",
    "        ('first_level_dm_paths', wf_firstlevel.get_firstlevel_dm.lzout.dm_paths),\n",
    "        ('first_level_contrast', wf_firstlevel.set_contrast.lzout.contrasts),\n",
    "        ('first_level_contrast_plot', wf_firstlevel.set_contrast.lzout.contrast_plot),\n",
    "        ('first_level_model_list', wf_firstlevel.firstlevel_estimation.lzout.first_level_model),\n",
    "        ('first_level_z_map_dict_list', wf_firstlevel.firstlevel_estimation.lzout.z_map_path_dict),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37f45f-2a57-4226-8e5c-fd58e3389a49",
   "metadata": {},
   "source": [
    "## Second-Level GLM\n",
    "\n",
    "The second-level estimation contains the following steps:\n",
    "- construct design matrix\n",
    "- fit the second-level GLM\n",
    "- thresholding & cluster analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061f24f0-213a-41d2-a262-2c1183596ad4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get second-level design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c14b6ee5-892e-4ca0-9ead-f13ddebc7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'n_subj': int, 'return': {'design_matrix': ty.Any}}\n",
    ")\n",
    "def get_secondlevel_dm(n_subj):\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"\\nGet secondlevel design matrix ...\\n\")\n",
    "    import pandas as pd\n",
    "    design_matrix = pd.DataFrame([1] * n_subj,columns=['intercept'])\n",
    "    dm_path = os.path.join(workflow_out_dir, 'secondlevel_designmatrix.csv')\n",
    "    design_matrix.to_csv(dm_path, index=None)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return design_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0648e6e-e96f-4626-b0d0-8259001b0eb6",
   "metadata": {},
   "source": [
    "### Fit the second level GLM\n",
    "\n",
    "Here, we use the list of fitted FirstLevelModel objects as the input for the SecondLevelModel, since all subjects share a similar design matrix (same variables reflected in column names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6547b8b3-cb5f-408c-bd12-11ab2fd1b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'second_level_input': ty.Any, 'design_matrix': ty.Any, 'firstlevel_contrast':list, \n",
    "     'return': {'secondlevel_mask': ty.Any, 'stat_maps_dict': dict}}\n",
    ")\n",
    "def secondlevel_estimation(second_level_input, design_matrix, firstlevel_contrast):\n",
    "    \"\"\" task to estimate the second level\n",
    "    Parameters\n",
    "    ----------\n",
    "    second_level_input : list\n",
    "        the list of FirstLevelModel\n",
    "    design_matrix : ty.Any\n",
    "        a pandas.DataFrame that specifies the second level design\n",
    "    firstlevel_contrast : dict\n",
    "        a dictionary of contrasts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    secondlevel_mask : mask from SecondLevelModel\n",
    "        \n",
    "    stat_maps_dict : dict\n",
    "        \n",
    "    \"\"\"\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"\\nStart secondlevel estimation ...\\n\")\n",
    "    from nilearn.glm.second_level import SecondLevelModel\n",
    "    second_level_model = SecondLevelModel()\n",
    "    second_level_model.fit(second_level_input, design_matrix=design_matrix)\n",
    "    secondlevel_mask = second_level_model.masker_.mask_img_\n",
    "    print('Computing contrasts...')\n",
    "    stat_maps_dict = {}\n",
    "    for index, (contrast_id, contrast_val) in enumerate(firstlevel_contrast[0].items()):\n",
    "        print('  Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(firstlevel_contrast[0]), contrast_id))\n",
    "        # Estimate the contasts. Note that the model implicitly computes a fixed\n",
    "        # effect across the two sessions\n",
    "        stat_maps = second_level_model.compute_contrast(first_level_contrast=contrast_val, output_type='all')\n",
    "        stat_maps_dict[contrast_id] = stat_maps\n",
    "        # # write the resulting stat images to file\n",
    "        # z_image_path = path.join(output_dir, 'contrast-%s_z_map.nii.gz' % contrast_id)\n",
    "        # z_image_path_list.append(z_image_path)\n",
    "        # z_map.to_filename(z_image_path)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return secondlevel_mask, stat_maps_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f9be0-cbd1-434f-be2f-02b8a36274ce",
   "metadata": {},
   "source": [
    "### Cluster-thresholding and Plot without multiple comparison\n",
    "\n",
    "Threshold the resulting map without multiple comparisons correction, abs(z) > 3.29 (equivalent to p < 0.001), cluster size > 10 voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8110f2e6-77e1-41f4-9484-42b154ca0360",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'stat_maps_dict': dict, 'threshold': float, 'cluster_threshold': int, \n",
    "     'return': {'thresholded_map_dict': dict, 'plot_contrast_dict': dict}}\n",
    ")\n",
    "def cluster_thresholding(stat_maps_dict, threshold, cluster_threshold):\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"\\nStart cluster thresholding ...\\n\")\n",
    "    from nilearn.image import threshold_img\n",
    "    from nilearn import plotting\n",
    "    thresholded_map_dict = dict.fromkeys(stat_maps_dict.keys())\n",
    "    plot_contrast_dict = dict.fromkeys(stat_maps_dict.keys())\n",
    "    for index, (stats_id, stats_val) in enumerate(stat_maps_dict.items()):\n",
    "        print('  Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(stat_maps_dict), stats_id))\n",
    "        thresholded_map = threshold_img(\n",
    "            img = stats_val['z_score'],\n",
    "            threshold=threshold,\n",
    "            cluster_threshold=cluster_threshold,\n",
    "            two_sided=True,\n",
    "        )\n",
    "        thresholded_map_path = path.join(workflow_out_dir, 'secondlevel_cluster_thresholded_contrast-%s_z_map.nii.gz' % stats_id)\n",
    "        thresholded_map_dict[stats_id] = thresholded_map_path\n",
    "        thresholded_map.to_filename(thresholded_map_path)\n",
    "        plot_path = os.path.join(workflow_out_dir, \n",
    "                                   'secondlevel_cluster_thresholded_contrast-%s_zmap.jpg' % stats_id)\n",
    "        plot_contrast_dict[stats_id] = plot_path\n",
    "        plotting.plot_stat_map(thresholded_map, cut_coords=[0],\n",
    "                               title='Cluster Thresholded z map',\n",
    "                               output_file=plot_path)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return thresholded_map_dict, plot_contrast_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca1bef-b4c8-43b4-b727-88843730d53c",
   "metadata": {},
   "source": [
    "### Multiple comparison and Plot\n",
    "\n",
    "We have the following choices:\n",
    "- `fdr`: False Discovery Rate (FDR <.05) and no cluster-level threshold\n",
    "- `fpr`: False Positive Rate\n",
    "- `bonferroni`\n",
    "\n",
    "More details see [here](https://nilearn.github.io/stable/modules/generated/nilearn.glm.threshold_stats_img.html#nilearn.glm.threshold_stats_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29f56355-4f0b-45e3-9d68-625726609693",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'stat_maps_dict': dict, 'alpha': float, 'height_control': str, \n",
    "     'return': {'thresholded_map_dict': dict, 'plot_contrast_dict': dict}}\n",
    ")\n",
    "def multiple_comparison(stat_maps_dict, alpha, height_control):\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"\\nStart multiple comparison ...\\n\")\n",
    "    from nilearn.glm import threshold_stats_img\n",
    "    from nilearn import plotting\n",
    "    thresholded_map_dict = dict.fromkeys(stat_maps_dict.keys())\n",
    "    plot_contrast_dict = dict.fromkeys(stat_maps_dict.keys())\n",
    "    for index, (stats_id, stats_val) in enumerate(stat_maps_dict.items()):\n",
    "        print('  Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(stat_maps_dict), stats_id))\n",
    "        thresholded_map, threshold = threshold_stats_img(\n",
    "            stat_img=stats_val['z_score'], \n",
    "            alpha=alpha, \n",
    "            height_control=height_control)\n",
    "        thresholded_map_path = os.path.join(workflow_out_dir, \n",
    "                                         'secondlevel_multiple_comp_corrected_contrast-%s_z_map.nii.gz' % stats_id)\n",
    "        thresholded_map_dict[stats_id] = thresholded_map_path\n",
    "        thresholded_map.to_filename(thresholded_map_path)\n",
    "        plot_path = os.path.join(workflow_out_dir, \n",
    "                                   'secondlevel_multiple_comp_corrected_contrast-%s_zmap.jpg' % stats_id)\n",
    "        plot_contrast_dict[stats_id] = plot_path\n",
    "        plotting.plot_stat_map(thresholded_ma,\n",
    "                               title='Thresholded z map, expected fdr = .05',\n",
    "                               threshold=threshold, \n",
    "                               output_file=plot_path)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return thresholded_map_dict, plot_contrast_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bf41ea-317d-435a-a19d-5ab8930a6838",
   "metadata": {},
   "source": [
    "### Paramatric test & Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e179490b-b20b-4a4a-bdb0-b31ed1158db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'stat_maps_dict': list, \n",
    "     'second_level_model': ty.Any,\n",
    "     'return': {'thresholded_map_dict': dict, 'plot_contrast_dict': dict}}\n",
    ")\n",
    "def parametric_test(stat_maps_dict, second_level_model):\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"\\nStart parametric test ...\\n\")\n",
    "    import numpy as np\n",
    "    from nilearn.image import get_data, math_img\n",
    "    from nilearn import plotting\n",
    "    thresholded_map_dict = dict.fromkeys(stat_maps_dict.keys())\n",
    "    plot_contrast_dict = dict.fromkeys(stat_maps_dict.keys())\n",
    "    for index, (stats_id, stats_val) in enumerate(stat_maps_dict.items()):\n",
    "        print('  Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(stat_maps_dict), stats_id))\n",
    "        p_val = stats_val['p_value']\n",
    "        n_voxels = np.sum(get_data(second_level_model.masker_.mask_img_))\n",
    "        # Correcting the p-values for multiple testing and taking negative logarithm\n",
    "        neg_log_pval = math_img(\"-np.log10(np.minimum(1, img * {}))\"\n",
    "                                .format(str(n_voxels)),\n",
    "                                img=p_val)\n",
    "        \n",
    "        thresholded_map_path = os.path.join(workflow_out_dir, 'secondlevel_paramatric_thresholded_contrast-%s_z_map.nii.gz' % stats_id)\n",
    "        thresholded_map_dict[stats_id] = thresholded_map_path\n",
    "        neg_log_pval.to_filename(thresholded_map_path)\n",
    "    \n",
    "        # Since we are plotting negative log p-values and using a threshold equal to 1,\n",
    "        # it corresponds to corrected p-values lower than 10%, meaning that there is\n",
    "        # less than 10% probability to make a single false discovery (90% chance that\n",
    "        # we make no false discovery at all).  This threshold is much more conservative\n",
    "        # than the previous one.\n",
    "        title = ('parametric test (FWER < 10%)')\n",
    "        plot_path = os.path.join(workflow_out_dir, \n",
    "                                   'secondlevel_paramatric_thresholded_contrast-%s_zmap.jpg' % stats_id)\n",
    "        plot_contrast_dict[stats_id] = plot_path\n",
    "        plotting.plot_glass_brain(\n",
    "            neg_log_pval, colorbar=True, display_mode='z', plot_abs=False, \n",
    "            vmax=3, threshold=1, title=title, output_file=plot_path)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    return thresholded_map_dict, plot_contrast_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e02d70a-6e04-407c-84f8-ba824c8b991d",
   "metadata": {},
   "source": [
    "### Non-paramatric test & Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de714c06-472f-49d0-a7d1-079007211085",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'second_level_input': list,'design_matrix': ty.Any, 'firstlevel_contrast': list, 'n_perm': int, \n",
    "     'return': {'thresholded_map_dict': dict, 'plot_contrast_dict': dict}}\n",
    ")\n",
    "def nonparametric_test(second_level_input, smoothing_fwhm, design_matrix, firstlevel_contrast, n_perm):\n",
    "    \"\"\" task to estimate the second level\n",
    "    Parameters\n",
    "    ----------\n",
    "    second_level_input : list\n",
    "        the list of first-level output (dictionary)\n",
    "    design_matrix : ty.Any\n",
    "        a pandas.DataFrame that specifies the second level design\n",
    "    firstlevel_contrast : dict\n",
    "        a dictionary of contrasts used in the first level\n",
    "    n_perm: int\n",
    "        number of permutation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    thresholded_map_dict : dict\n",
    "        \n",
    "    plot_contrast_dict : dict\n",
    "        \n",
    "    \"\"\"\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"\\nStart nonparametric test ...\\n\")\n",
    "    from nilearn.glm.second_level import non_parametric_inference\n",
    "    from nilearn import plotting\n",
    "    thresholded_map_dict = dict.fromkeys(firstlevel_contrast[0].keys())\n",
    "    plot_contrast_dict = dict.fromkeys(firstlevel_contrast[0].keys())\n",
    "    for index, (contrast_id, contrast_val) in enumerate(firstlevel_contrast[0].items()):\n",
    "        print('  Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(firstlevel_contrast[0]), contrast_id))\n",
    "        # here we set threshold as none to do voxel-level FWER-correction.\n",
    "        neg_log_pvals_permuted_ols_unmasked = \\\n",
    "            non_parametric_inference(second_level_input=second_level_input, design_matrix=design_matrix,\n",
    "                                     model_intercept=True, n_perm=n_perm,first_level_contrast=contrast_val,\n",
    "                                     two_sided_test=False, smoothing_fwhm=smoothing_fwhm, n_jobs=1)\n",
    "        print(\"test1...\")\n",
    "        thresholded_map_path = os.path.join(workflow_out_dir, 'secondlevel_permutation_contrast-%s_z_map.nii.gz' % contrast_id)\n",
    "        print(\"test2...\")\n",
    "        thresholded_map_dict[contrast_id] = thresholded_map_path\n",
    "        print(\"test3...\")\n",
    "        neg_log_pvals_permuted_ols_unmasked.to_filename(thresholded_map_path)\n",
    "        # here I actually have more than one contrast\n",
    "        title = ('permutation test (FWER < 10%)')\n",
    "        plot_path = os.path.join(workflow_out_dir, 'secondlevel_permutation_contrast-%s_zmap.jpg' % contrast_id)\n",
    "        plot_contrast_dict[contrast_id] = plot_path\n",
    "        display = plotting.plot_glass_brain(\n",
    "            neg_log_pvals_permuted_ols_unmasked, colorbar=True, vmax=3,\n",
    "            display_mode='z', plot_abs=False, threshold=1, \n",
    "            title=title, output_file=plot_path)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2-t1)\n",
    "    print(f\"thresholded_map_dict = {thresholded_map_dict}\")\n",
    "    print(f\"plot_contrast_dict = {plot_contrast_dict}\")\n",
    "    return thresholded_map_dict, plot_contrast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "908df4e1-f766-4337-b395-ad6ff878b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'test_input1':ty.Any,\n",
    "        'test_input2': ty.Any,\n",
    "        'return': {'out1':ty.Any, 'out2':ty.Any}\n",
    "    }\n",
    ")\n",
    "def test1(test_input1, test_input2):\n",
    "    print(\"testing...\")\n",
    "    out1 = test_input1\n",
    "    out2 = test_input2\n",
    "    return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3853d89-df16-4621-8a24-6ba06bcbb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'test_input1':ty.Any,\n",
    "        'test_input2': ty.Any,\n",
    "        'return': {'out1':ty.Any, 'out2':ty.Any}\n",
    "    }\n",
    ")\n",
    "def test2(test_input1, test_input2):\n",
    "    print(\"testing...\")\n",
    "    out1 = test_input1\n",
    "    out2 = test_input2\n",
    "    return out1, out2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c4126c-890f-4239-93e1-5ef0cb1f8d44",
   "metadata": {},
   "source": [
    "### Create the second-level GLM workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "958ad1f1-05be-4c60-843d-aec2cf999b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the first-level GLM workflow\n",
    "wf_secondlevel = Workflow(\n",
    "    name='wf_secondlevel',\n",
    "    input_spec=[\n",
    "        'n_subj',\n",
    "        'second_level_input', \n",
    "        'smoothing_fwhm',\n",
    "        'firstlevel_contrast',\n",
    "        'n_perm',\n",
    "        'output_dir'\n",
    "    ],\n",
    ")\n",
    "\n",
    "# add task - get_secondlevel_dm\n",
    "wf_secondlevel.add(\n",
    "    get_secondlevel_dm(\n",
    "        name = \"get_secondlevel_dm\",\n",
    "        n_subj = wf_secondlevel.lzin.n_subj, \n",
    "    )\n",
    ")\n",
    "\n",
    "# # add task - secondlevel_estimation\n",
    "# wf_secondlevel.add(\n",
    "#     secondlevel_estimation(\n",
    "#         name = \"secondlevel_estimation\",\n",
    "#         second_level_input = wf_secondlevel.lzin.second_level_input,  \n",
    "#         design_matrix = wf_secondlevel.get_secondlevel_dm.lzout.design_matrix, \n",
    "#         firstlevel_contrast = wf_secondlevel.lzin.firstlevel_contrast\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # add task - secondlevel_estimation\n",
    "# wf_secondlevel.add(\n",
    "#     cluster_thresholding(\n",
    "#         name = \"cluster_thresholding\",\n",
    "#         stat_maps_dict = wf_secondlevel.secondlevel_estimation.lzout.stat_maps_dict, \n",
    "#         threshold = 3.29, \n",
    "#         cluster_threshold = 10\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # add task - multiple_comparison\n",
    "# wf_secondlevel.add(\n",
    "#     multiple_comparison(\n",
    "#         name = \"multiple_comparison\",\n",
    "#         stat_maps_dict = wf_secondlevel.secondlevel_estimation.lzout.stat_maps_dict, \n",
    "#         alpha = 0.05,\n",
    "#         height_control = 'fdr'\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # add task - parametric_test\n",
    "# wf_secondlevel.add(\n",
    "#     parametric_test(\n",
    "#         name = \"parametric_test\",\n",
    "#         stat_maps_dict = wf_secondlevel.secondlevel_estimation.lzout.stat_maps_dict, \n",
    "#         second_level_model = wf_secondlevel.secondlevel_estimation.lzout.second_level_model\n",
    "#     )\n",
    "    \n",
    "# )\n",
    "\n",
    "# add task - nonparametric_test\n",
    "wf_secondlevel.add(\n",
    "    nonparametric_test(\n",
    "        name = \"nonparametric_test\",\n",
    "        second_level_input = wf_secondlevel.lzin.second_level_input,\n",
    "        smoothing_fwhm = wf_secondlevel.lzin.smoothing_fwhm, \n",
    "        design_matrix = wf_secondlevel.get_secondlevel_dm.lzout.design_matrix, \n",
    "        firstlevel_contrast = wf_secondlevel.lzin.firstlevel_contrast, \n",
    "        n_perm = wf_secondlevel.lzin.n_perm,\n",
    "    )\n",
    ")\n",
    "\n",
    "# wf_secondlevel.add(\n",
    "#     test1(\n",
    "#         name = \"test1\",\n",
    "#         test_input1 = wf_secondlevel.get_secondlevel_dm.lzout.design_matrix, \n",
    "#         test_input2 = wf_secondlevel.get_secondlevel_dm.lzout.design_matrix)\n",
    "# )\n",
    "\n",
    "# wf_secondlevel.add(\n",
    "#     test2(\n",
    "#         name = \"test2\",\n",
    "#         test_input1 = wf_secondlevel.test1.lzout.out1, \n",
    "#         test_input2 = wf_secondlevel.test1.lzout.out2)\n",
    "# )\n",
    "# specify output\n",
    "wf_secondlevel.set_output(\n",
    "    [\n",
    "        # # ('second_level_clusterthresholding_result', wf_secondlevel.cluster_thresholding.lzout.thresholded_map_dict),\n",
    "        # ('second_level_clusterthresholding_plot', wf_secondlevel.cluster_thresholding.lzout.plot_contrast_dict),\n",
    "        # ('second_level_mc_result', wf_secondlevel.multiple_comparison.lzout.thresholded_map_dict),\n",
    "        # ('second_level_mc_plot', wf_secondlevel.multiple_comparison.lzout.plot_contrast_dict),\n",
    "        # ('second_level_parametric_test', wf_secondlevel.parametric_test.lzout.thresholded_map_dict),\n",
    "        # ('second_level_parametric_plot', wf_secondlevel.parametric_test.lzout.plot_contrast_dict),\n",
    "        ('second_level_nonparametric_test', wf_secondlevel.nonparametric_test.lzout.thresholded_map_dict),\n",
    "        ('second_level_nonparametric_plot', wf_secondlevel.nonparametric_test.lzout.plot_contrast_dict),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5b3512-953b-4c68-a166-c3dd7059cb04",
   "metadata": {},
   "source": [
    "## The Ultimate Workflow\n",
    "\n",
    "Now, let's connect all tasks and workflows together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4d51840-f8dd-4c99-9f53-6dd41aa55afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow(\n",
    "    name='twolevel_glm',\n",
    "    input_spec=['subj_id', 'rawdata_url', 'fmriprep_url', 'smoothing_fwhm', 'output_dir'],\n",
    ")\n",
    "\n",
    "wf.inputs.rawdata_url = 'https://github.com/OpenNeuroDerivatives/ds000001-fmriprep.git'\n",
    "wf.inputs.fmriprep_url = 'https://github.com/OpenNeuroDatasets/ds000001.git'\n",
    "wf.inputs.smoothing_fwhm = 5.0\n",
    "wf.inputs.output_dir = workflow_out_dir\n",
    "\n",
    "wf.add(\n",
    "    get_data(\n",
    "        name = \"get_data\",\n",
    "        rawdata_url = wf.lzin.rawdata_url, \n",
    "        fmriprep_url = wf.lzin.fmriprep_url)\n",
    ")\n",
    "n_subj = 3\n",
    "wf_firstlevel.inputs.subj_id = [x for x in range(n_subj)]\n",
    "wf_firstlevel.inputs.n_run = 3\n",
    "wf_firstlevel.inputs.tr = 2.3\n",
    "wf_firstlevel.inputs.n_scans = 300\n",
    "wf_firstlevel.inputs.hrf_model = 'glover'\n",
    "wf_firstlevel.inputs.event_list = wf.get_data.lzout.event_list\n",
    "wf_firstlevel.inputs.img_list = wf.get_data.lzout.img_list\n",
    "wf_firstlevel.inputs.mask_list = wf.get_data.lzout.mask_list\n",
    "wf_firstlevel.inputs.smoothing_fwhm = wf.lzin.smoothing_fwhm\n",
    "wf_firstlevel.inputs.output_dir = wf.lzin.output_dir\n",
    "wf.add(wf_firstlevel)\n",
    "\n",
    "wf_secondlevel.inputs.n_subj = n_subj\n",
    "wf_secondlevel.inputs.second_level_input = wf.wf_firstlevel.lzout.first_level_model_list \n",
    "wf_secondlevel.inputs.smoothing_fwhm = wf.lzin.smoothing_fwhm\n",
    "wf_secondlevel.inputs.firstlevel_contrast = wf.wf_firstlevel.lzout.first_level_contrast\n",
    "wf_secondlevel.inputs.n_perm = 1\n",
    "wf_secondlevel.inputs.output_dir = wf.lzin.output_dir\n",
    "wf.add(wf_secondlevel)\n",
    "\n",
    "wf.set_output(\n",
    "    [\n",
    "        ('first_level_outputs', wf.wf_firstlevel.lzout.first_level_z_map_dict_list),\n",
    "        # ('second_level_clusterthresholding_result', wf.wf_secondlevel.lzout.second_level_clusterthresholding_result),\n",
    "        # ('second_level_clusterthresholding_plot', wf.wf_secondlevel.lzout.second_level_clusterthresholding_plot),\n",
    "        # ('second_level_mc_result', wf.wf_secondlevel.lzout.second_level_mc_result),\n",
    "        # ('second_level_mc_plot', wf.wf_secondlevel.lzout.second_level_mc_plot),\n",
    "        # ('second_level_parametric_test', wf.wf_secondlevel.lzout.second_level_parametric_test),\n",
    "        # ('second_level_parametric_plot', wf.wf_secondlevel.lzout.second_level_parametric_plot),\n",
    "        ('second_level_nonparametric_test', wf.wf_secondlevel.lzout.second_level_nonparametric_test),\n",
    "        ('second_level_nonparametric_plot', wf.wf_secondlevel.lzout.second_level_nonparametric_plot),    \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ea4f822-7acf-4110-87b5-970c973cf239",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download data...\n",
      "2022-08-15 19:46:06.193378\n",
      "0:00:00.796122\n",
      "\n",
      "Get subject-1 file...\n",
      "\n",
      "Get subject-2 file...\n",
      "\n",
      "\n",
      "Get subject-3 file...\n",
      "\n",
      "\n",
      "0:00:00.0057340:00:00.005641\n",
      "0:00:00.005292\n",
      "\n",
      "\n",
      "Get subject-1 firstlevel GLM ...\n",
      "\n",
      "\n",
      "Get subject-2 firstlevel GLM ...\n",
      "\n",
      "\n",
      "Get subject-3 firstlevel GLM ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/__init__.py:56: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  'It may change in any future release of Nilearn.', FutureWarning)\n",
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/__init__.py:56: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  'It may change in any future release of Nilearn.', FutureWarning)\n",
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/__init__.py:56: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  'It may change in any future release of Nilearn.', FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:01.499939\n",
      "0:00:01.669759\n",
      "0:00:01.689029\n",
      "\n",
      "Set firstlevel contrast for subject-3 ...\n",
      "\n",
      "\n",
      "Set firstlevel contrast for subject-2 ...\n",
      "\n",
      "\n",
      "Set firstlevel contrast for subject-1 ...\n",
      "\n",
      "  Plot Contrast  1 out of 5: pumps-control  Plot Contrast  1 out of 5: pumps-control\n",
      "\n",
      "  Plot Contrast  1 out of 5: pumps-control\n",
      "  Plot Contrast  2 out of 5: control-pumps\n",
      "  Plot Contrast  2 out of 5: control-pumps  Plot Contrast  2 out of 5: control-pumps\n",
      "\n",
      "  Plot Contrast  3 out of 5: pumps-baseline\n",
      "  Plot Contrast  3 out of 5: pumps-baseline\n",
      "  Plot Contrast  3 out of 5: pumps-baseline\n",
      "  Plot Contrast  4 out of 5: cash-baseline\n",
      "  Plot Contrast  4 out of 5: cash-baseline\n",
      "  Plot Contrast  4 out of 5: cash-baseline\n",
      "  Plot Contrast  5 out of 5: explode-baseline\n",
      "  Plot Contrast  5 out of 5: explode-baseline\n",
      "  Plot Contrast  5 out of 5: explode-baseline\n",
      "0:00:08.021898\n",
      "0:00:08.101115\n",
      "0:00:08.090936\n",
      "\n",
      "Start firstlevel estimation for subject-1 ...\n",
      "\n",
      "\n",
      "Start firstlevel estimation for subject-3 ...\n",
      "\n",
      "Compute firstlevel mask...\n",
      "\n",
      "Start firstlevel estimation for subject-2 ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/__init__.py:56: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  'It may change in any future release of Nilearn.', FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute firstlevel mask...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/__init__.py:56: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  'It may change in any future release of Nilearn.', FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute firstlevel mask...\n",
      "Computing contrasts...\n",
      "  Contrast  1 out of 5: pumps-control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py:657: UserWarning: One contrast given, assuming it for all 3 runs\n",
      "  warn('One contrast given, assuming it for all %d runs' % n_runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Contrast  2 out of 5: control-pumps\n",
      "Computing contrasts...\n",
      "  Contrast  1 out of 5: pumps-control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py:657: UserWarning: One contrast given, assuming it for all 3 runs\n",
      "  warn('One contrast given, assuming it for all %d runs' % n_runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing contrasts...\n",
      "  Contrast  1 out of 5: pumps-control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py:657: UserWarning: One contrast given, assuming it for all 3 runs\n",
      "  warn('One contrast given, assuming it for all %d runs' % n_runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Contrast  3 out of 5: pumps-baseline\n",
      "  Contrast  4 out of 5: cash-baseline\n",
      "  Contrast  2 out of 5: control-pumps\n",
      "  Contrast  2 out of 5: control-pumps\n",
      "  Contrast  5 out of 5: explode-baseline\n",
      "  Contrast  3 out of 5: pumps-baseline\n",
      "0:03:42.686623\n",
      "  Contrast  3 out of 5: pumps-baseline\n",
      "  Contrast  4 out of 5: cash-baseline\n",
      "  Contrast  4 out of 5: cash-baseline\n",
      "  Contrast  5 out of 5: explode-baseline\n",
      "  Contrast  5 out of 5: explode-baseline\n",
      "0:03:49.347410\n",
      "0:03:49.899925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/__init__.py:56: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  'It may change in any future release of Nilearn.', FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get secondlevel design matrix ...\n",
      "\n",
      "0:00:00.023547\n",
      "\n",
      "Start nonparametric test ...\n",
      "\n",
      "  Contrast  1 out of 5: pumps-control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py:657: UserWarning: One contrast given, assuming it for all 3 runs\n",
      "  warn('One contrast given, assuming it for all %d runs' % n_runs)\n",
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/mass_univariate/permuted_least_squares.py:504: UserWarning: The specified number of permutations is 1 and the number of jobs to be performed in parallel has set to 1. This is incompatible so only 1 jobs will be running. You may want to perform more permutations in order to take the most of the available computing ressources.\n",
      "  'ressources.' % (n_perm, n_jobs, n_perm))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1...\n",
      "test2...\n",
      "test3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibeichen/miniconda3/envs/pydra/lib/python3.7/site-packages/nilearn/plotting/displays/_slicers.py:383: UserWarning: empty mask\n",
      "  get_mask_bounds(new_img_like(img, not_mask, affine))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Contrast  2 out of 5: control-pumps\n",
      "test1...\n",
      "test2...\n",
      "test3...\n",
      "  Contrast  3 out of 5: pumps-baseline\n",
      "test1...\n",
      "test2...\n",
      "test3...\n",
      "  Contrast  4 out of 5: cash-baseline\n",
      "test1...\n",
      "test2...\n",
      "test3...\n",
      "  Contrast  5 out of 5: explode-baseline\n",
      "test1...\n",
      "test2...\n",
      "test3...\n",
      "0:00:37.384914\n",
      "thresholded_map_dict = {'pumps-control': '/Users/yibeichen/GDrive/GitHub/pydra-tutorial/outputs/7_glm/results/secondlevel_permutation_contrast-pumps-control_z_map.nii.gz', 'control-pumps': '/Users/yibeichen/GDrive/GitHub/pydra-tutorial/outputs/7_glm/results/secondlevel_permutation_contrast-control-pumps_z_map.nii.gz', 'pumps-baseline': '/Users/yibeichen/GDrive/GitHub/pydra-tutorial/outputs/7_glm/results/secondlevel_permutation_contrast-pumps-baseline_z_map.nii.gz', 'cash-baseline': '/Users/yibeichen/GDrive/GitHub/pydra-tutorial/outputs/7_glm/results/secondlevel_permutation_contrast-cash-baseline_z_map.nii.gz', 'explode-baseline': '/Users/yibeichen/GDrive/GitHub/pydra-tutorial/outputs/7_glm/results/secondlevel_permutation_contrast-explode-baseline_z_map.nii.gz'}\n",
      "plot_contrast_dict = {'pumps-control': '/Users/yibeichen/GDrive/GitHub/pydra-tutorial/outputs/7_glm/results/secondlevel_permutation_contrast-pumps-control_zmap.jpg', 'control-pumps': '/Users/yibeichen/GDrive/GitHub/pydra-tutorial/outputs/7_glm/results/secondlevel_permutation_contrast-control-pumps_zmap.jpg', 'pumps-baseline': '/Users/yibeichen/GDrive/GitHub/pydra-tutorial/outputs/7_glm/results/secondlevel_permutation_contrast-pumps-baseline_zmap.jpg', 'cash-baseline': '/Users/yibeichen/GDrive/GitHub/pydra-tutorial/outputs/7_glm/results/secondlevel_permutation_contrast-cash-baseline_zmap.jpg', 'explode-baseline': '/Users/yibeichen/GDrive/GitHub/pydra-tutorial/outputs/7_glm/results/secondlevel_permutation_contrast-explode-baseline_zmap.jpg'}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'errored'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wr/x5xt_yqs2cvc_gb3sf147lvc0000gn/T/ipykernel_65920/815201263.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mSubmitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_procs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msubmitter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msubmitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pydra/lib/python3.7/site-packages/pydra/engine/submitter.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, runnable, cache_locations, rerun)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcache_locations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_locations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit_from_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunnable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrerun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pydra/lib/python3.7/site-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     88\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pydra/lib/python3.7/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pydra/lib/python3.7/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pydra/lib/python3.7/site-packages/pydra/engine/submitter.py\u001b[0m in \u001b[0;36msubmit_from_call\u001b[0;34m(self, runnable, rerun)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mawait\u001b[0m \u001b[0mrunnable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrerun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrerun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;31m# 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pydra/lib/python3.7/site-packages/pydra/engine/core.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, submitter, rerun, **kwargs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m                 \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrerun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrerun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collect_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pydra/lib/python3.7/site-packages/pydra/engine/core.py\u001b[0m in \u001b[0;36m_run_task\u001b[0;34m(self, submitter, rerun)\u001b[0m\n\u001b[1;32m   1110\u001b[0m                 \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# at this point Workflow is stateless so this should be fine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         \u001b[0;32mawait\u001b[0m \u001b[0msubmitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_workflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrerun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrerun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pydra/lib/python3.7/site-packages/pydra/engine/submitter.py\u001b[0m in \u001b[0;36mexpand_workflow\u001b[0;34m(self, wf, rerun)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# expand that workflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mis_workflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                     \u001b[0;32mawait\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrerun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrerun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0;31m# single task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pydra/lib/python3.7/site-packages/pydra/engine/core.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, submitter, rerun, **kwargs)\u001b[0m\n\u001b[1;32m   1083\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrerun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrerun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collect_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m                 \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pydra/lib/python3.7/site-packages/pydra/engine/core.py\u001b[0m in \u001b[0;36m_collect_outputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all connections must be lazy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m                 \u001b[0mval_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m                 \u001b[0moutput_wf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pydra/lib/python3.7/site-packages/pydra/engine/specs.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, wf, state_index)\u001b[0m\n\u001b[1;32m    769\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mresults_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrored\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error from get_value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'errored'"
     ]
    }
   ],
   "source": [
    "from pydra import Submitter\n",
    "\n",
    "with Submitter(plugin='cf', n_procs=8) as submitter:\n",
    "    submitter(wf)\n",
    "\n",
    "results = wf.result()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f67ea-d9e7-4b92-88b1-cbe2e75c51de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
